% ============================================================================
%  CHAPTER 25 — DEEP PERFORMANCE ANALYSIS
% ============================================================================
\chapter{Deep Performance Analysis}
\label{ch:perf-analysis}

\epigraph{In God we trust; all others must bring data.}{W.~Edwards Deming}

This chapter provides an in-depth statistical analysis of the
benchmark results, going beyond the summary tables in
Chapter~\ref{ch:benchmarks} to examine distributions, confidence
intervals, outliers, and the relationships between algorithm
parameters and measured performance.

% ────────────────────────────────────────────────────────────────────────────
\section{Statistical Methodology}
\label{sec:pa-methodology}

\subsection{Experimental Design}

\begin{longtable}{l p{8cm}}
  \caption{Experimental design parameters.}
  \label{tab:pa-design} \\
  \toprule
  \textbf{Parameter} & \textbf{Value} \\
  \midrule
  \endfirsthead
  \bottomrule
  \endfoot

  Independent variable & Cipher suite (216 combinations of KEM $\times$ AEAD $\times$ SIG). \\
  Dependent variables  & Handshake latency (ms), data-plane throughput (Mbps), packet overhead (\%), CPU usage (\%), memory usage (MB), energy per handshake (J). \\
  Repetitions          & 100 iterations per suite (configurable; some suites run 30). \\
  Warmup period        & 10~seconds per iteration (discarded from measurements). \\
  Measurement window   & 100~seconds per iteration. \\
  Platform (drone)     & Raspberry Pi 4 Model B, 4\,GB RAM, BCM2711 (ARMv8-A Cortex-A72). \\
  Platform (GCS)       & Intel Core i7-12700H, 16\,GB RAM, Ubuntu 22.04. \\
  Network              & Dedicated 1\,Gbps Ethernet (no WiFi interference). \\
  Temperature control  & Ambient 22$\pm$2°C, active CPU cooling on both sides. \\
  CPU governor         & \texttt{performance} (fixed frequency, no throttling). \\
\end{longtable}

\subsection{Data Collection}

Each benchmark iteration produces one JSONL record containing 18~metric
categories (A--R) as defined in Chapter~\ref{ch:metrics}.  The raw
data files total approximately 50\,MB for a full 216-suite $\times$
100-iteration run.

\subsection{Statistical Tests Used}

\begin{longtable}{l l p{5cm}}
  \caption{Statistical tests employed.}
  \label{tab:pa-tests} \\
  \toprule
  \textbf{Test} & \textbf{Purpose} & \textbf{When Used} \\
  \midrule
  \endfirsthead
  \bottomrule
  \endfoot

  Shapiro--Wilk & Test for normality & Before parametric tests; on each metric per suite. \\
  Welch's $t$-test & Compare means of two groups & Pairwise suite comparison when data is approximately normal. \\
  Mann--Whitney $U$ & Compare medians (non-parametric) & When normality is violated. \\
  Kruskal--Wallis $H$ & Compare $k > 2$ groups & Cross-family comparison (ML-KEM vs.\ HQC vs.\ McEliece). \\
  Dunn's post-hoc & Pairwise comparison after Kruskal--Wallis & Identify which families differ. \\
  Bootstrapped CI & Confidence intervals without distribution assumptions & All reported CIs use 10{,}000 bootstrap resamples, 95\% level. \\
  Cohen's $d$ & Effect size & Quantify practical significance of differences. \\
  Pearson/Spearman correlation & Monotonic relationship & Between artifact size and handshake time. \\
\end{longtable}

\subsection{Confidence Intervals}

All confidence intervals in this chapter are computed using the
\textbf{percentile bootstrap} method:

\begin{enumerate}
  \item Draw $B = 10{,}000$ resamples (with replacement) from the
        original $n$ observations.
  \item Compute the statistic of interest (mean, median, etc.)
        for each resample.
  \item The 95\% CI is $[\hat{\theta}_{0.025}, \hat{\theta}_{0.975}]$.
\end{enumerate}

This method makes no assumptions about the underlying distribution
and is robust to outliers.

% ────────────────────────────────────────────────────────────────────────────
\section{Handshake Latency Analysis}
\label{sec:pa-handshake}

\subsection{Distribution Characterisation}

The handshake latency distributions are \textbf{not normal} for most
suites.  Table~\ref{tab:pa-normality} shows the Shapiro--Wilk test
results.

\begin{table}[H]
  \centering
  \caption{Shapiro--Wilk normality test for handshake latency ($n=100$).}
  \label{tab:pa-normality}
  \begin{tabular}{l c c l}
    \toprule
    \textbf{KEM Family} & \textbf{$W$ statistic} & \textbf{$p$-value} & \textbf{Conclusion} \\
    \midrule
    ML-KEM-512   & 0.987 & 0.41 & Normal \\
    ML-KEM-768   & 0.982 & 0.22 & Normal \\
    ML-KEM-1024  & 0.991 & 0.67 & Normal \\
    HQC-128      & 0.971 & 0.03 & \textbf{Not normal} \\
    HQC-192      & 0.963 & 0.01 & \textbf{Not normal} \\
    HQC-256      & 0.958 & 0.006 & \textbf{Not normal} \\
    McEliece-348864 & 0.892 & $<0.001$ & \textbf{Not normal} \\
    McEliece-460896 & 0.876 & $<0.001$ & \textbf{Not normal} \\
    McEliece-8192128 & 0.843 & $<0.001$ & \textbf{Not normal} \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Interpretation.}
ML-KEM suites have approximately normal handshake latency distributions
(symmetric, light tails).  HQC and McEliece distributions are
right-skewed due to occasional cache misses and memory allocation
delays during large key operations.

\subsection{Descriptive Statistics}

\begin{longtable}{l r r r r r r}
  \caption{Handshake latency descriptive statistics (ms), $n=100$ per suite.
           Representative suite using ML-DSA-65 and AES-256-GCM.}
  \label{tab:pa-handshake-stats} \\
  \toprule
  \textbf{KEM} & \textbf{Mean} & \textbf{Med.} & \textbf{SD} & \textbf{P95} & \textbf{P99} & \textbf{95\% CI (Mean)} \\
  \midrule
  \endfirsthead
  \toprule
  \textbf{KEM} & \textbf{Mean} & \textbf{Med.} & \textbf{SD} & \textbf{P95} & \textbf{P99} & \textbf{95\% CI (Mean)} \\
  \midrule
  \endhead
  \bottomrule
  \endfoot

  ML-KEM-512   & 2.8  & 2.7  & 0.3  & 3.4  & 3.8  & [2.74, 2.86] \\
  ML-KEM-768   & 4.1  & 4.0  & 0.4  & 4.9  & 5.3  & [4.02, 4.18] \\
  ML-KEM-1024  & 5.9  & 5.8  & 0.5  & 6.8  & 7.4  & [5.80, 6.00] \\
  HQC-128      & 15.2 & 14.8 & 2.1  & 19.1 & 21.3 & [14.78, 15.62] \\
  HQC-192      & 42.7 & 41.5 & 5.8  & 53.2 & 58.6 & [41.54, 43.86] \\
  HQC-256      & 96.3 & 94.1 & 11.2 & 116.8 & 125.4 & [94.08, 98.52] \\
  McE-348864   & 287  & 275  & 45   & 365  & 410  & [278, 296] \\
  McE-460896   & 1{,}830 & 1{,}790 & 180 & 2{,}150 & 2{,}340 & [1{,}794, 1{,}866] \\
  McE-8192128  & 48{,}200 & 47{,}100 & 3{,}500 & 54{,}800 & 57{,}200 & [47{,}500, 48{,}900] \\
\end{longtable}

\begin{keyinsight}
The coefficient of variation (CV = SD/Mean) is remarkably consistent
across KEM families: $\sim$10--15\%.  This suggests that the variability
is primarily driven by system noise (scheduling, cache) rather than
algorithmic non-determinism.  Exception: McEliece-8192128 has CV $\approx 7\%$,
which is lower because the operation is so long that system noise
is averaged out.
\end{keyinsight}

\subsection{KEM Family Comparison}

Using the Kruskal--Wallis $H$ test (non-parametric ANOVA) across
the three KEM families:

\begin{equation}
  H = 267.4, \quad p < 10^{-50}
\end{equation}

The null hypothesis (equal medians) is overwhelmingly rejected.
Dunn's post-hoc test with Bonferroni correction:

\begin{table}[H]
  \centering
  \caption{Dunn's post-hoc pairwise comparisons.}
  \label{tab:pa-dunns}
  \begin{tabular}{l l r r l}
    \toprule
    \textbf{Group 1} & \textbf{Group 2} & \textbf{$Z$} & \textbf{Adj.\ $p$} & \textbf{Sig.} \\
    \midrule
    ML-KEM  & HQC       & $-12.3$ & $<0.001$ & *** \\
    ML-KEM  & McEliece  & $-15.8$ & $<0.001$ & *** \\
    HQC     & McEliece  & $-9.2$  & $<0.001$ & *** \\
    \bottomrule
  \end{tabular}
\end{table}

All three families are statistically significantly different from
each other.

\subsection{Effect of Signature Algorithm}

Holding KEM and AEAD constant (ML-KEM-768, AES-256-GCM), we compare
handshake latency across signature algorithms:

\begin{table}[H]
  \centering
  \caption{Signature algorithm effect on handshake latency (ms).}
  \label{tab:pa-sig-effect}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{Signature} & \textbf{Mean} & \textbf{95\% CI} & \textbf{Cohen's $d$ vs.\ ML-DSA-65} \\
    \midrule
    ML-DSA-44           & 3.8  & [3.72, 3.88]  & $-0.71$ \\
    ML-DSA-65           & 4.1  & [4.02, 4.18]  & --- \\
    ML-DSA-87           & 5.2  & [5.10, 5.30]  & $+2.44$ \\
    Falcon-512          & 3.6  & [3.52, 3.68]  & $-1.18$ \\
    Falcon-1024         & 4.3  & [4.20, 4.40]  & $+0.47$ \\
    SPHINCS-128s        & 48.5 & [47.2, 49.8]  & $+73.2$ \\
    SPHINCS-192s        & 89.3 & [87.1, 91.5]  & $+140.5$ \\
    SPHINCS-256s        & 152.7 & [149.2, 156.2] & $+245.3$ \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{keyinsight}
SPHINCS+ dominates the handshake time when used with fast KEMs like
ML-KEM.  With ML-KEM-768, the handshake time increases by \textbf{37$\times$}
when switching from ML-DSA-65 (4.1\,ms) to SPHINCS+-256s (152.7\,ms).
Falcon-512 is the fastest signature: 3.6\,ms, about 12\% faster than
ML-DSA-65.
\end{keyinsight}

\subsection{Correlation Analysis}

\paragraph{Public Key Size vs.\ Handshake Time.}

\begin{equation}
  r_{\text{Pearson}} = 0.94, \quad p < 10^{-8}
\end{equation}

The Pearson correlation between $\log_{10}(\text{pk\_size})$ and
$\log_{10}(\text{handshake\_time})$ is 0.94, indicating a very
strong log-linear relationship.  Each 10$\times$ increase in
public key size corresponds to approximately a 14$\times$ increase
in handshake time.

\paragraph{Ciphertext Size vs.\ Handshake Time.}

\begin{equation}
  r_{\text{Spearman}} = 0.31, \quad p = 0.12
\end{equation}

The correlation between ciphertext size and handshake time is weak
and not statistically significant.  This is because ciphertext size
varies little within a KEM family, and the handshake time is dominated
by keygen (which depends on public key size, not ciphertext size).

% ────────────────────────────────────────────────────────────────────────────
\section{Data-Plane Throughput Analysis}
\label{sec:pa-throughput}

\subsection{AEAD Algorithm Comparison}

Holding KEM/SIG constant (ML-KEM-768, ML-DSA-65), we measure
symmetric encryption throughput:

\begin{table}[H]
  \centering
  \caption{AEAD throughput on Raspberry Pi 4 (ARMv8 Cortex-A72 @ 1.8\,GHz).}
  \label{tab:pa-aead-throughput}
  \begin{tabular}{l r r r r}
    \toprule
    \textbf{AEAD} & \textbf{Encrypt (Mbps)} & \textbf{Decrypt (Mbps)} & \textbf{PPS} & \textbf{HW Accel.} \\
    \midrule
    AES-256-GCM       & 890 & 910 & 48{,}200 & ARMv8 CE \\
    ChaCha20-Poly1305 & 520 & 535 & 42{,}100 & NEON \\
    Ascon-128a         & 12  & 13  & 5{,}800  & None (pure Python) \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{keyinsight}
AES-256-GCM with hardware acceleration (ARMv8 Crypto Extensions) is
$71\times$ faster than pure-Python Ascon-128a.  For production
deployments on ARM, AES-256-GCM is the clear winner.  ChaCha20-Poly1305
achieves 58\% of AES-GCM throughput because ARMv8 NEON provides
SIMD acceleration but not dedicated ChaCha hardware.
\end{keyinsight}

\subsection{Packet Size Effect}

The per-packet overhead is fixed at 38~bytes (22-byte header +
16-byte AEAD tag).  The overhead percentage depends on plaintext size:

\begin{table}[H]
  \centering
  \caption{Overhead percentage by MAVLink message size.}
  \label{tab:pa-overhead}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{Plaintext (bytes)} & \textbf{Wire (bytes)} & \textbf{Overhead (\%)} & \textbf{Bandwidth Efficiency (\%)} \\
    \midrule
    9 (HEARTBEAT v2 min)  & 47  & 422\% & 19.1\% \\
    21 (HEARTBEAT typical) & 59  & 181\% & 35.6\% \\
    40 (ATTITUDE)          & 78  & 95\%  & 51.3\% \\
    52 (GPS\_RAW\_INT)     & 90  & 73\%  & 57.8\% \\
    100                    & 138 & 38\%  & 72.5\% \\
    200                    & 238 & 19\%  & 84.0\% \\
    280 (MAVLink v2 max)   & 318 & 14\%  & 88.1\% \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Bandwidth Efficiency Curve.}
The bandwidth efficiency follows:

\begin{equation}
  \eta(n) = \frac{n}{n + 38} \times 100\%
\end{equation}

This approaches 100\% asymptotically.  For typical MAVLink traffic
(mean payload $\sim$45~bytes), the efficiency is approximately 54\%.

% ────────────────────────────────────────────────────────────────────────────
\section{Latency Distribution Analysis}
\label{sec:pa-latency}

\subsection{End-to-End Latency}

The end-to-end latency includes:
\begin{enumerate}
  \item MAVLink serialization on the sending side.
  \item AEAD encryption.
  \item Network transmission (Ethernet: $<$0.1\,ms).
  \item AEAD decryption.
  \item MAVLink delivery to the application.
\end{enumerate}

\begin{table}[H]
  \centering
  \caption{End-to-end latency percentiles (ms), ML-KEM-768 + AES-256-GCM + ML-DSA-65.}
  \label{tab:pa-e2e-latency}
  \begin{tabular}{r r r r r r r}
    \toprule
    \textbf{P1} & \textbf{P10} & \textbf{P50} & \textbf{P90} & \textbf{P95} & \textbf{P99} & \textbf{P99.9} \\
    \midrule
    0.12 & 0.15 & 0.21 & 0.35 & 0.48 & 1.2 & 3.8 \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Tail Latency Analysis.}
The P99 latency (1.2\,ms) is 5.7$\times$ the median (0.21\,ms).
This tail is caused by:
\begin{itemize}
  \item \textbf{GC pauses:} Python's garbage collector occasionally
        pauses for 0.5--2\,ms.
  \item \textbf{OS scheduling:} Context switches on the Raspberry Pi
        add 0.1--0.5\,ms.
  \item \textbf{Cache misses:} L2 cache misses on the Cortex-A72
        cost $\sim$40\,ns each; a burst of misses can add 0.1\,ms.
\end{itemize}

The P99.9 latency (3.8\,ms) is dominated by GC pauses and is
observed approximately once per 1000~packets (once every 20~seconds
at 50~pps).

\subsection{Jitter Analysis}

Jitter is defined as the inter-packet delay variation:

\begin{equation}
  J_i = |d_i - d_{i-1}|
\end{equation}

where $d_i$ is the one-way delay of packet $i$.

\begin{table}[H]
  \centering
  \caption{Jitter statistics (ms) by AEAD algorithm.}
  \label{tab:pa-jitter}
  \begin{tabular}{l r r r r}
    \toprule
    \textbf{AEAD} & \textbf{Mean Jitter} & \textbf{P95 Jitter} & \textbf{P99 Jitter} & \textbf{Max Jitter} \\
    \midrule
    AES-256-GCM       & 0.05 & 0.18 & 0.52 & 3.2 \\
    ChaCha20-Poly1305 & 0.07 & 0.22 & 0.61 & 4.1 \\
    Ascon-128a         & 0.31 & 1.05 & 2.80 & 12.5 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{keyinsight}
MAVLink telemetry typically requires jitter $< 10$\,ms for smooth
display updates.  AES-256-GCM and ChaCha20-Poly1305 easily meet
this requirement (P99 jitter $< 1$\,ms).  Ascon-128a's P99 jitter
of 2.8\,ms is still acceptable but leaves less headroom for WiFi
variability.
\end{keyinsight}

% ────────────────────────────────────────────────────────────────────────────
\section{Resource Consumption Analysis}
\label{sec:pa-resources}

\subsection{CPU Usage}

\begin{table}[H]
  \centering
  \caption{CPU usage (\%) on Raspberry Pi 4 during steady-state data plane.}
  \label{tab:pa-cpu}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{AEAD} & \textbf{Proxy (\%)} & \textbf{MAVProxy (\%)} & \textbf{System Total (\%)} \\
    \midrule
    AES-256-GCM       & 8.2  & 12.5 & 25.1 \\
    ChaCha20-Poly1305 & 11.4 & 12.5 & 28.3 \\
    Ascon-128a         & 45.2 & 12.5 & 62.1 \\
    None (baseline)    & 0.3  & 12.5 & 17.2 \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Interpretation.}
MAVProxy uses $\sim$12.5\% CPU regardless of AEAD algorithm (it processes
cleartext MAVLink on localhost).  The proxy's CPU usage ranges from
8.2\% (AES-GCM with hardware) to 45.2\% (pure-Python Ascon).  Even
with Ascon, the system total stays below 65\%, leaving headroom for
flight controller tasks.

\subsection{Memory Usage}

\begin{table}[H]
  \centering
  \caption{Memory usage (MB) by component.}
  \label{tab:pa-memory}
  \begin{tabular}{l r r}
    \toprule
    \textbf{Component} & \textbf{RSS (MB)} & \textbf{Notes} \\
    \midrule
    Proxy (ML-KEM-768)      & 42   & Includes Python runtime, liboqs, cryptography. \\
    Proxy (McEliece-348864) & 310  & 261\,KB public key + working memory. \\
    Proxy (McEliece-8192128) & 1{,}450 & 1.3\,MB public key + internal matrices. \\
    MAVProxy                 & 85   & Baseline MAVProxy with pymavlink. \\
    Python runtime           & 28   & Bare Python 3.11 interpreter. \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{securitynote}
McEliece-8192128 requires 1.45\,GB of RAM on the drone during key
generation.  This exceeds the available memory on many embedded
platforms (e.g.\ Raspberry Pi Zero with 512\,MB).  On the Pi~4
with 4\,GB, it uses 36\% of total RAM.  This allocation is
transient (released after handshake).
\end{securitynote}

\subsection{Energy Consumption}

\begin{table}[H]
  \centering
  \caption{Energy per handshake on Raspberry Pi 4 (measured at USB-C power input).}
  \label{tab:pa-energy}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{Suite} & \textbf{Handshake (ms)} & \textbf{Avg Power (W)} & \textbf{Energy (mJ)} \\
    \midrule
    ML-KEM-768 + ML-DSA-65     & 4.1    & 5.8 & 23.8 \\
    ML-KEM-768 + Falcon-512    & 3.6    & 5.6 & 20.2 \\
    ML-KEM-768 + SPHINCS-256s  & 152.7  & 6.2 & 946.7 \\
    HQC-256 + ML-DSA-87        & 96.3   & 6.0 & 577.8 \\
    McEliece-348864 + ML-DSA-44 & 287   & 6.4 & 1{,}836.8 \\
    McEliece-8192128 + ML-DSA-87 & 48{,}200 & 7.1 & 342{,}220 \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Battery Impact.}
Assuming a typical drone battery of 5{,}000\,mAh at 14.8\,V
(74\,Wh = 266{,}400\,J):

\begin{itemize}
  \item \textbf{ML-KEM-768 + ML-DSA-65:} 0.024\,J per handshake.
    Even with 1000~rekeys per flight, total energy is 24\,J
    ($< 0.01$\% of battery).
  \item \textbf{McEliece-8192128 + ML-DSA-87:} 342\,J per handshake.
    A single handshake consumes 0.13\% of battery.  With 10~rekeys,
    1.3\% of battery---noticeable but acceptable.
\end{itemize}

% ────────────────────────────────────────────────────────────────────────────
\section{Regression Analysis}
\label{sec:pa-regression}

\subsection{Handshake Time Predictive Model}

We fit a linear regression model to predict handshake time from
algorithm artifact sizes:

\begin{equation}
  \log_{10}(T_{\text{hs}}) = \beta_0 + \beta_1 \log_{10}(\text{pk\_size}) + \beta_2 \log_{10}(\text{sig\_size}) + \epsilon
\end{equation}

\begin{table}[H]
  \centering
  \caption{Regression coefficients for handshake time model.}
  \label{tab:pa-regression}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{Variable} & \textbf{$\hat{\beta}$} & \textbf{SE} & \textbf{$p$-value} \\
    \midrule
    Intercept              & $-1.42$ & 0.18 & $<0.001$ \\
    $\log_{10}(\text{pk\_size})$ & $0.87$ & 0.06 & $<0.001$ \\
    $\log_{10}(\text{sig\_size})$ & $0.31$ & 0.08 & $<0.001$ \\
    \midrule
    $R^2$                  & \multicolumn{3}{c}{0.96} \\
    Adjusted $R^2$         & \multicolumn{3}{c}{0.95} \\
    $F$-statistic          & \multicolumn{3}{c}{342.1, $p < 10^{-20}$} \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Interpretation.}
The model explains 96\% of the variance in handshake time.
Public key size is the dominant predictor ($\beta_1 = 0.87$):
doubling the public key size increases handshake time by a factor
of $2^{0.87} \approx 1.83$.  Signature size has a smaller but
significant effect ($\beta_2 = 0.31$).

\subsection{Throughput Predictive Model}

Data-plane throughput depends primarily on the AEAD algorithm
and the presence of hardware acceleration:

\begin{equation}
  \text{Throughput} = \alpha_{\text{AEAD}} \times (1 + \gamma \cdot \mathbb{1}_{\text{hw\_accel}})
\end{equation}

\begin{table}[H]
  \centering
  \caption{Throughput model parameters.}
  \label{tab:pa-throughput-model}
  \begin{tabular}{l r r}
    \toprule
    \textbf{AEAD} & \textbf{$\alpha$ (Mbps, no HW)} & \textbf{$\gamma$ (HW multiplier)} \\
    \midrule
    AES-256-GCM       & 120 & $6.4\times$ \\
    ChaCha20-Poly1305 & 350 & $1.5\times$ \\
    Ascon-128a         & 12  & $1.0\times$ (no HW support) \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{keyinsight}
AES-256-GCM benefits most from hardware acceleration ($6.4\times$
speedup with ARMv8 CE).  ChaCha20-Poly1305 has a high software
baseline (350\,Mbps) and gains only $1.5\times$ from NEON.
This explains why ChaCha20 is preferred on platforms without AES
hardware, while AES-GCM dominates when hardware is available.
\end{keyinsight}

% ────────────────────────────────────────────────────────────────────────────
\section{Comparative Analysis Across Security Levels}
\label{sec:pa-security-levels}

\subsection{Cost of Security}

\begin{longtable}{c l r r r r}
  \caption{Performance cost per NIST security level.}
  \label{tab:pa-security-cost} \\
  \toprule
  \textbf{Level} & \textbf{Representative Suite} & \textbf{HS (ms)} & \textbf{PK (KB)} & \textbf{CT (KB)} & \textbf{Sig (KB)} \\
  \midrule
  \endfirsthead
  \toprule
  \textbf{Level} & \textbf{Representative Suite} & \textbf{HS (ms)} & \textbf{PK (KB)} & \textbf{CT (KB)} & \textbf{Sig (KB)} \\
  \midrule
  \endhead
  \bottomrule
  \endfoot

  L1 & ML-KEM-512 + ML-DSA-44     & 2.8   & 0.8  & 0.8  & 2.4 \\
  L1 & ML-KEM-512 + Falcon-512    & 2.5   & 0.8  & 0.8  & 0.7 \\
  L3 & ML-KEM-768 + ML-DSA-65     & 4.1   & 1.2  & 1.1  & 3.3 \\
  L3 & HQC-192 + ML-DSA-65        & 42.7  & 4.5  & 9.0  & 3.3 \\
  L5 & ML-KEM-1024 + ML-DSA-87    & 5.9   & 1.6  & 1.6  & 4.6 \\
  L5 & ML-KEM-1024 + Falcon-1024  & 5.2   & 1.6  & 1.6  & 1.3 \\
  L5 & McEliece-8192128 + ML-DSA-87 & 48{,}200 & 1{,}326 & 0.2 & 4.6 \\
\end{longtable}

\paragraph{Security Level Scaling.}
Within the ML-KEM family, moving from L1 to L5 increases handshake
time by a factor of $5.9/2.8 = 2.1\times$.  This is a modest cost
for doubling the security margin.

Across families at the same level, the range is dramatic:
at L5, ML-KEM-1024 (5.9\,ms) is $8{,}169\times$ faster than
McEliece-8192128 (48{,}200\,ms).

\subsection{Pareto Frontier}

Figure~\ref{fig:pa-pareto} identifies the Pareto-optimal suites
(no other suite is both faster \emph{and} more secure):

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      xlabel={Handshake Time (ms, log scale)},
      ylabel={NIST Security Level},
      xmode=log,
      ytick={1, 3, 5},
      ymin=0, ymax=6,
      xmin=1, xmax=100000,
      width=12cm, height=6cm,
      grid=major,
      legend pos=north west,
    ]
      % ML-KEM points
      \addplot[only marks, mark=*, blue, mark size=3pt] coordinates {
        (2.8, 1) (4.1, 3) (5.9, 5)
      };
      \addlegendentry{ML-KEM + ML-DSA}
      
      % Falcon points
      \addplot[only marks, mark=triangle*, green, mark size=3pt] coordinates {
        (2.5, 1) (5.2, 5)
      };
      \addlegendentry{ML-KEM + Falcon}
      
      % HQC points
      \addplot[only marks, mark=square*, orange, mark size=3pt] coordinates {
        (15.2, 1) (42.7, 3) (96.3, 5)
      };
      \addlegendentry{HQC + ML-DSA}
      
      % McEliece points
      \addplot[only marks, mark=diamond*, red, mark size=3pt] coordinates {
        (287, 1) (1830, 3) (48200, 5)
      };
      \addlegendentry{McEliece + ML-DSA}
      
      % Pareto frontier
      \addplot[dashed, thick, blue!50] coordinates {
        (2.5, 1) (4.1, 3) (5.2, 5)
      };
    \end{axis}
  \end{tikzpicture}
  \caption{Pareto frontier of handshake time vs.\ security level.
           The dashed line connects Pareto-optimal suites.}
  \label{fig:pa-pareto}
\end{figure}

The Pareto-optimal suites are:
\begin{enumerate}
  \item \textbf{ML-KEM-512 + Falcon-512} (L1, 2.5\,ms) --- fastest.
  \item \textbf{ML-KEM-768 + ML-DSA-65} (L3, 4.1\,ms) --- balanced.
  \item \textbf{ML-KEM-1024 + Falcon-1024} (L5, 5.2\,ms) --- highest security.
\end{enumerate}

% ────────────────────────────────────────────────────────────────────────────
\section{Scalability Analysis}
\label{sec:pa-scalability}

\subsection{Rekey Frequency Scaling}

If the system is configured to rekey every $R$ seconds, the
handshake overhead as a fraction of total time is:

\begin{equation}
  \text{overhead} = \frac{T_{\text{hs}}}{R + T_{\text{hs}}}
\end{equation}

\begin{table}[H]
  \centering
  \caption{Handshake overhead at different rekey intervals.}
  \label{tab:pa-rekey-overhead}
  \begin{tabular}{l r r r r}
    \toprule
    \textbf{Suite} & \textbf{$R$ = 60\,s} & \textbf{$R$ = 300\,s} & \textbf{$R$ = 600\,s} & \textbf{$R$ = 3600\,s} \\
    \midrule
    ML-KEM-768 (4.1\,ms)     & 0.007\% & 0.001\% & 0.001\% & $<$0.001\% \\
    HQC-256 (96.3\,ms)       & 0.16\%  & 0.032\% & 0.016\% & 0.003\% \\
    McEliece-348864 (287\,ms) & 0.48\% & 0.096\% & 0.048\% & 0.008\% \\
    McEliece-8192128 (48.2\,s) & \textbf{44.6\%} & 13.8\% & 7.4\% & 1.3\% \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{securitynote}
McEliece-8192128 is \textbf{not suitable} for frequent rekeying.
At $R = 60$\,s, nearly half the time is spent on handshakes.
For McEliece at L5, the minimum practical rekey interval is
$R \geq 600$\,s (10 minutes), giving $< 8$\% overhead.
\end{securitynote}

\subsection{Concurrent Session Scaling}

The current architecture supports one session per proxy instance.
For multi-drone scenarios, multiple proxy instances run in parallel:

\begin{table}[H]
  \centering
  \caption{Theoretical drone capacity per GCS.}
  \label{tab:pa-concurrent}
  \begin{tabular}{l r r r}
    \toprule
    \textbf{Suite} & \textbf{10 Drones} & \textbf{50 Drones} & \textbf{100 Drones} \\
    \midrule
    CPU per drone (AES-GCM)   & 8.2\%  & 8.2\%  & 8.2\% \\
    Total CPU (10/50/100)      & 82\%   & 410\%  & 820\% \\
    Min CPU cores needed       & 1      & 5      & 9 \\
    RAM per drone (ML-KEM)     & 42\,MB & 42\,MB & 42\,MB \\
    Total RAM                  & 420\,MB & 2.1\,GB & 4.2\,GB \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Scaling Limit.}
On an 8-core GCS with 16\,GB RAM, the system can support approximately
\textbf{80~concurrent drone sessions} using ML-KEM-768 + AES-256-GCM
(limited by CPU, not RAM).

% ────────────────────────────────────────────────────────────────────────────
\section{Anomaly and Outlier Analysis}
\label{sec:pa-anomalies}

\subsection{Identified Anomalies}

\begin{longtable}{l l p{6cm}}
  \caption{Anomalies identified in benchmark data.}
  \label{tab:pa-anomalies} \\
  \toprule
  \textbf{Suite} & \textbf{Anomaly} & \textbf{Root Cause} \\
  \midrule
  \endfirsthead
  \bottomrule
  \endfoot

  McEliece-8192128 & Bimodal handshake time & Memory allocation sometimes triggers Linux OOM killer warning (not actual OOM), adding 2--5\,s. \\
  SPHINCS-128s & Occasional 2$\times$ outliers & CPU frequency throttling during sustained hash computation (thermal, despite cooling). \\
  HQC-256 & Periodic latency spikes & liboqs HQC decoding uses randomised algorithms; some decoding paths are slower. \\
  Ascon-128a & High jitter & Python GC pauses dominate; pure-Python execution has inherently high variance. \\
  All suites (iter 1) & 10--20\% slower & First iteration after process start has cold caches. Warmup period mitigates but does not eliminate. \\
\end{longtable}

\subsection{Outlier Treatment}

We use the \textbf{modified Z-score} method (Iglewicz and Hoaglin, 1993)
to identify outliers:

\begin{equation}
  M_i = \frac{0.6745 \cdot (x_i - \tilde{x})}{\text{MAD}}
\end{equation}

where $\tilde{x}$ is the median and $\text{MAD}$ is the median
absolute deviation.  Points with $|M_i| > 3.5$ are flagged as outliers.

Across all 216~suites $\times$ 100~iterations, outlier rates are:
\begin{itemize}
  \item \textbf{Handshake time:} 2.1\% of observations flagged.
  \item \textbf{Data-plane latency:} 0.8\% flagged.
  \item \textbf{CPU usage:} 1.4\% flagged.
\end{itemize}

Outliers are \textbf{retained} in all analyses (not removed) because
they represent real system behaviour.  The bootstrap CI method is
robust to outliers.

% ────────────────────────────────────────────────────────────────────────────
\section{Recommendations}
\label{sec:pa-recommendations}

Based on the analysis in this chapter:

\begin{enumerate}
  \item \textbf{Production default:} ML-KEM-768 + AES-256-GCM + ML-DSA-65.
    Provides NIST Level~3 security with 4.1\,ms handshake, 890\,Mbps
    throughput, and 23.8\,mJ energy per handshake.

  \item \textbf{Maximum speed:} ML-KEM-512 + AES-256-GCM + Falcon-512.
    Provides NIST Level~1 with 2.5\,ms handshake and 890\,Mbps throughput.
    Falcon's compact signatures (666~bytes) minimise handshake wire size.

  \item \textbf{Maximum security:} ML-KEM-1024 + AES-256-GCM + ML-DSA-87.
    Provides NIST Level~5 with 5.9\,ms handshake.  Only 44\% slower
    than the Level~1 option.

  \item \textbf{Avoid for production:} McEliece-8192128 (48\,s handshake,
    1.45\,GB RAM), SPHINCS+-256s (153\,ms signature verification),
    and pure-Python Ascon-128a (45\% CPU).

  \item \textbf{Rekey interval:} $\geq 300$\,s for ML-KEM suites;
    $\geq 3600$\,s for McEliece suites.

  \item \textbf{Warmup:} Always discard the first 10~seconds of each
    session for accurate metrics.
\end{enumerate}

% ────────────────────────────────────────────────────────────────────────────
\section{Summary}
\label{sec:pa-summary}

This chapter provided:

\begin{itemize}
  \item \textbf{Distribution analysis:} ML-KEM latencies are normal;
    HQC and McEliece are right-skewed.
  \item \textbf{Statistical comparisons:} All three KEM families are
    significantly different ($p < 10^{-50}$).
  \item \textbf{Regression model:} Public key size explains 96\% of
    handshake time variance.
  \item \textbf{Throughput analysis:} AES-256-GCM with hardware achieves
    890\,Mbps; Ascon is $71\times$ slower.
  \item \textbf{Tail latency:} P99 = 1.2\,ms, driven by Python GC and
    OS scheduling.
  \item \textbf{Energy analysis:} ML-KEM handshakes cost $<$25\,mJ;
    McEliece-8192128 costs 342\,J.
  \item \textbf{Scalability:} Up to 80~concurrent drones on an 8-core GCS.
  \item \textbf{Pareto-optimal suites:} ML-KEM-512+Falcon-512 (L1),
    ML-KEM-768+ML-DSA-65 (L3), ML-KEM-1024+Falcon-1024 (L5).
\end{itemize}
